---
layout:     post
title:      "图像分割实操与经验之谈"
subtitle:   " \"基于深度学习的语义分割的个人实操经验之谈\""
date:       2019-05-23 01:57:00
author:     "HeShuai"
header-img: "img/banner/dataflow.jpg"
catalog: true
tags:
    - Deeplearning
	- Segmentation
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# 图像分割实操与经验之谈

### 0. 前话

> 个人做图像分割算法相关的满打有差不多四年的时间，但不是学术导向的纵向挖掘，而是横向应用。16年中开始做了几个月的OCR区域分割，以传统分割算法为主，后面短暂做了一段时间的基于DL的试卷区域分割，然后是实验室的机器人导航视觉系统的避障地图分割，到最近的视频流人像分割。其实严格上来说我不是在做分割算法，而是用分割算法（狗头）:dog:。
>
> 本文主要是最近基于深度学习的人像分割项目上的一些实操经验蒸馏与总结，算是对自己的一个交代，同时希望能贡献点经验给在实验室两眼抓瞎的师弟妹。另外其实人家也还是~~宝宝~~小师弟，因此可能会犯经验上的错，如果大佬觉有不对之处，望不吝赐教:grin:。



### 1.  概要

> 所谓深度学习就是百万数据+超级模型+黄老板核弹:boom:暴力调参

> 本文从个人认为最重要的三个方面进行构文总结：数据、模型以及调参。对于深度学习，数据是一切之先。数据收集、优化以及挖掘值得投入百分之60以上的精力；模型是数据确定之后，但模型改进跟买彩票一样，提升幅度也很有限，最简单的就是去针对你的任务的benchmark从第一名扫下来，去github扒，总有一款适合你；最后就是老中医调参，调参的目的在于挖掘在你目前的数据、模型以及训练相关的上限。总的来说，重要程度：
>
> > 数据 > 调参 > 模型选择



### 2. 数据

数据

### 3. Metrics
https://stats.stackexchange.com/questions/273537/f1-dice-score-vs-iou/276144#276144


### 4. 模型选择

上你业务性能允许的最大计算量的模型

### 4.调参

根据先验构建一个调参空间

统计metric的方差和均值一样重要
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/20200323113707.png)
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/20200323113723.png)

