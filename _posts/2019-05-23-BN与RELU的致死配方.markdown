---
layout:     post
title:      "BN与ReLU的致死配方"
subtitle:   " \"BN与ReLU搭配使用时会出现死区现象\""
date:       2019-05-23 01:57:00
author:     "HeShuai"
header-img: "img/banner/post-default.jpg"
catalog: true
tags:
    - 深度学习
	- 分割
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# BN与ReLU的致死配方

### 前话

> 最近一直想把Spatial Attention做到分割当中，进行具有空间选择性的语义特征和高分辨率特征融合。但是过程中发现shortcut过来的高分辨率特征居然是无视输入的常量，即是我的shortcut被完全忽视了，神经网络仅仅采用了语义特征。一开始我怀疑是我的ATTENTION结构的问题，就了检查一些中间输出，然后发现不仅仅shortcut当中出现这种问题，mobilenetv2 backbone当中也存在这种现象。
>
> 简单来说，上述问题其实是BN+ReLU结构中ReLU出现了死区。死因本人遭遇的有两种：BN的scale和bias主动学习，使得BN的输出恒负诱发ReLU死区；第二种则跟BN无关，BN的输入即为无限接近于0，因此ReLU进入死区。以上两种死区现象都可以单独从过BN的四个参数进行快速判断，而无需可视化中间变量或者在Tensorboard里面看ReLU输出histogram。最后提供一个tf.keras custom callback监控BN以预警死区乃至一般的参数异常。



### 1.  BN-ReLU blcok

如今深度学习视觉里面convolution+batch normalization+relu三明治近乎是一个标准结构，应用于各种模型当中。本文不讨论卷积部分，仅仅讨论三明治的下两层BN-RELU结构。

**复习一下BN的[数学过程](https://medium.com/@krishna_84429/understanding-batch-normalization-1eaca8f2f63e)：**

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200212222212.png)

在上面的计算过程中，BN层存在四个重要的参数：

$$\mu_{B}$$: 滑动均值，训练过程中的滑动均值，反应BN输入的统计平均。

$$\sigma_B$$：滑动方差，训练过程中的滑动方差，反应BN输入的波动程度。

$$\gamma$$：缩放因子，可学习变量，缩放正态归一后的输出

$$\beta$$：偏置量，科学系变量，缩放正太归一化输出的偏置。以上四个参数在推理阶段均为常量。

**ReLU的数学过程：**


$$
y=f(x)=\begin{cases}
x&,x\geq0 \\ 
0&,x<0
\end{cases}
$$


那么BN-ReLU block的输出即为两者的嵌套:


$$
y = f_{relu}(f_{bn}(x)) = f_{relu}(\gamma \hat{x_{i}} + \beta)
$$


### 2. BN-ReLU block的异常现象

在个人经历中，BN-ReLU组合会出现两种问题。第一种我愿称为主动式BN信息拒绝问题；第二种则是ReLU死区问题。

##### 2.1 主动式BN信息拒绝

如前所说，个人尝试在分割当中引入空间注意力结构，试图选择性地融合来源于深层卷积输出的语义特征和来自表层卷积输出的低维度特征。这个其实是现有分割模型喜闻乐见的shortcut结构，不同仅在于两种不同层次特征融合方式。以下是网络图的简要结构示意：

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200212230153.png)

训练了一段时间，发现相对baseline没有任何提升，于是可视化了ATTENTION模块的一些中间结果。结果发现，shortcut过来的Low Level Feature（BN-ReLU的输出）居然全是0，即是全空的。那我要这~~铁棒~~shorcut有何用！（下图是当时纳闷之余保留的结果）

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200212230717.png)

**问题所在**

如前所述，BN存在两个可学习参数$$\gamma$$和$$\beta$$。两个可学习参数的意义在于线性缩放BN归一化的结果。然而，当$$\gamma$$趋向于0而$$\beta<0$$时，有：


$$
y_{bn} = \gamma \hat{x_i} + \beta \approx 0* \hat{x_i} + \beta = \beta< 0
$$


此时BN的输出就已经是一个小于0的定值，与输入无关了。再经过ReLU，得到的特征全部置零。结果就是上面shortcut过来的信息被BN-ReLU完全拦截掉。此时查一下BN的两个值，基本上$$\gamma <10^{-30}$$, 而$$\beta \approx -1.x$$。

**个人理解**

为何称为“主动式信息拒绝”，是因为BN的输入看起来是正常的，但是BN的两个可学习参数不正常，结合ReLU的门效应，直接拒掉了这个信息。为何会出现这个问题，个人猜测是我的attention结构设计不太合理，导致了神经网络在优化过程中觉得来自shortcut的信息要还不如不要，因此直接拒绝了。梯度反传的原理就是往梯度最大的方向优化，大学习率可能会加重这个问题。

后面我为了避免这个问题，在shortcut中采用了BN+Sigmoid的结构，结果BN参数和shortcut特征都正常了，但是收敛极其缓慢。直到最后ATTENTION结构也没发挥出我期待的效果:dog:。

##### 2.2 BN正常但是仍进入死区

上述的遭遇让我对BN投了不信任票，因此检查了所有的BN层参数和ReLU层可视化输出，结果（老师的小眼睛一眯觉得事情并不简单呐）：

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200213014634.png)

上图为一个分割模型mobilenetv2 backbone中expanded_conv5_expand_relu的输出，可见有相当一部分比例的特征通道输出是空的，即ReLU在该维度进入了死区（虽然不至于像上面shortcut那样通通死掉）。随便找一个维度，查看其前面BN的参数：


$$
\gamma = 1.5588417053222656\\
\beta = -1.3605622053146362 \\
 \mu = 1.0585836836320366e^{-37}\\
 \sigma = 1.0648686754003491e^{-37}
$$


可见BN的两个学习参数看起来挺正常的，但是滑动均值和滑动方差异常的小。几乎为0的均值和方差说明BN在该维度的输入是一个脉冲信号，就是0。此时，$x_i \approx0$，有：


$$
y_{i} = \gamma \hat{x_i} + \beta = \gamma* \frac{x_i - \mu}{\sqrt{\sigma^2+\varepsilon}} +\beta\\ 
\approx \gamma* \frac{0}{\sqrt{\sigma^2+\varepsilon}} +\beta\\ 
= \beta < 0
$$


再经过ReLU，嚄嚯！来跟死区say hi。

**个人理解**

此种条件下的死区并非BN引起的，而是BN的输入就为0，拿掉BN后续ReLU也会假死（输出无限逼近于0）。假如是一个CONV+BN+RELU三明治结构，则说明CONV在某个维度上的卷积核L1异常的小，为一个无用卷积核。

### 3. 死区检测

从前两个小标的内容就可以判断出BN的四个参数跟死区问题息息相关，或者互为体现。因此，可以通过BN参数快速判断出存在BN-ReLU模块的神经网络中是否存在死区现象，在训练初期就将其扼杀在摇篮里。

当出现主动BN信息拒绝时，BN参数的模式：


$$
\gamma < 10^{-30}\\
\beta <0 \\
 \mu ：无\\
 \sigma ：无
$$


当出现一般死区问题，BN参数的模式：


$$
\gamma ：无\\
\beta <0 \\
 \mu <10^{-30}\\
 \sigma <10^{-30}
$$


简化来说，只要BN出现了极度异常小的值（事实上神经网络上任何如此极端的值都值得注意），那恭喜你喜提死区:boom:。

死区的出现务必在训练初期就检测出来，否则后训练阶段已经无力回天了。这里提供一个tf.keras.callback，实时监控每个epoch的参数异常情况。参数异常的定义为参数极端大或者极端小，不仅仅局限于本文提到的BN结构。

```python
class AbnormalWeightCheck(Callback):
    """
    raise warning if extreme weights are detected every n epoch.
    result logged into a file named as the model
    # usage sample
		ab_weights_callback = AbnormalWeightCheck()
		you_model = ...
		you_model.fit(..., callback=[ab_weights_callback])	
    """

    def __init__(self, log_dir,
                 log_name=None,
                 warning_threshold=1e5,  # abs(value) > threshold
                 # or
                 # abs(value) < [1 / (threshold)]
                 warning_factor=0.,  # mini fraction of abnormal values in a weight metric to raise warning
                 epoch_period=10,  # detection step/epoch
                 verbose=True):
        super(AbnormalWeightCheck, self).__init__()
        self.log_dir = log_dir
        self.epoch_period = epoch_period
        self._verbose = verbose
        self.warning_threshold = warning_threshold
        self.warning_factor = warning_factor
        self.log_name = log_name
        self.logger = None

    def _init_logger(self):
        if self.log_name is None:
            self.log_name = self.model.name
        self.logger = logging.getLogger(self.log_name)
        logging_level = logging.INFO if self._verbose else logging.ERROR
        self.logger.setLevel(logging_level)
        self.log_file = self.log_name + '_abnormal_weights.log'
        self.log_file = os.path.join(self.log_dir, self.log_file)
        ch = logging.FileHandler(self.log_file)
        ch.setLevel(logging_level)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        ch.setFormatter(formatter)
        self.logger.addHandler(ch)

    def weight_analyse(self):
        """
        detect weights with extreme value
        :param model:
        :return:
        """
        warning_dict = {}
        for item in self.model.weights:
            weights_value = K.get_value(item)
            w_name = item.name
            abnormal_factor = (np.sum(np.abs(weights_value) > self.warning_threshold) + \
                               np.sum(np.abs(weights_value) < (1. / self.warning_threshold)))
            if abnormal_factor > 0:
                warning_dict[w_name] = abnormal_factor / float(weights_value.size)
        # warning_dict = sorted(warning_dict.items(), key=warning_dict.values)
        return warning_dict

    def on_epoch_end(self, epoch, logs=None):
        if self.logger is None:
            self._init_logger()
        if epoch % self.epoch_period == 0:
            warning_dict = self.weight_analyse()
            self.logger.warning(warning_dict)

```

以下为本人训练的一个模型的真实检测结果：

> 2020-02-13 15:05:56,378 - WARNING - 
>
> 'Structure/weights' : abormal proportion
>
> 'Conv/bias:0': 0.125, 
>
> 'expanded_conv_depthwise_BN/moving_mean:0': 0.25, 
>
> 'expanded_conv_depthwise_BN/moving_variance:0': 0.25, 
>
> 'expanded_conv_project/kernel:0': 0.5234375
>
> ...

### 后话

模型某些层处于死亡状态，没有生成任何特征，因此模型的真实表达容量会被削弱。另那部分死亡的结构会徒增无效计算，影响模型大小和推理效率。

死区问题的应对有两种方法：训练时避免、后训练阶段剪裁。训练时避免死区的方式比较多，如控制参数初始化或者直接的模型修改如替换激活函数等；有些人会argue说死区现象是模型稀疏化的一种策略，丢弃无用甚至消极的特征，因此是正常的，训练阶段无需理会。但是这会带来推理阶段的无效计算。对于这种情况，可以后训练阶段graph层次优化的时候裁剪掉无效的层和结构，从而降低推理计算量和模型大小，利于部署。

另不排除上述遇到的两个问题是工程bug或者个人参数初始化有问题引起的。网上搜索了一番，没找到有人提到相关问题，所以总结出如此一篇博文。如果看到这的大佬发现了端倪，请评论/联系指教。:heart:



### TODO

1. 增加一个小节讨论如何避免训练时死区问题
2. 增加一个小节介绍如果后处理阶段裁剪掉死亡的无用结构