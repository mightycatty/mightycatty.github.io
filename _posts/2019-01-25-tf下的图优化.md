---
layout:     post
title:      "图优化"
subtitle:   " \"静态图优化\""
date:       2019-01-15 22:02:00
author:     "HeShuai"
header-img: "img/banner/post-default.jpg"
catalog: true
tags:
    - 推理
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>


# 图优化

## 0. 前话

> 训练所得的tensorflow下的图（graph）不能直接用于推理测部署，需要进行针对性图优化。所谓图优化是指图层次的优化，与具体设备、硬件情况和推理框架无关。优化结果可以用于不同的推理框架或者硬件中，并进行下一步更低层次的优化。比图优化层次更低的是算子优化和kernel优化等，此类优化会考虑硬件情况，如CPU/GPU的不同特性考虑等。与训练图相比，图优化的结果更精简，去除推理无关或者不影响推理结果的节点，合并相关层，算术的优化，以及图体积上的减小。

## 1.  概要

静态图是tf采用的一种计算图机制（虽然很多人都在骂并开始拥护pytorch），

## 2. 概念部分

### 2.1 静态图 vs 动态图

最近fast.ai和deepmind都开始站到了pytorch的阵营中，吸引他们转营的一个重要因素就是：pytorch是动态图机制而TF是静态图机制。动态图是指其中运算按照代码编写顺序执行，运行一步定义一步再执行一步；静态图机制则将计算定义与运行时分析，在编译时即完成计算的全部定义。

pytorch和tensorflow的对立与python和c++的对立有些类似，因此他们的优缺点也类似：

| 机制   | 代表框架         | 优点                                                         | 缺点                                                 |
| ------ | ---------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
| 静态图 | tensorflow mxnet | 无需重复定义、理论上更好的性能、稳定、独立优化、方便移动portable | 新思路新结构开发低效、难以debug、定义与运行分离      |
| 动态图 | pytorch          | 编写代码顺序执行，支持逻辑流，快速高效灵活                   | 理论上更差的性能、不适用于性能和稳定性优先的落地部署 |

就如为性能考虑，落地工程以c++为开发一样，目前深度学习落地侧仍以（仅以）静态图为主。静态图将图定义与运行时分离，可以实现独立于运行时的优化，且compile once run everywhere，可以用于不同的推理后端。图优化正是基于静态图的这个特点。

### 2.2 表达层

### 2.2 图优化的在落地pipeline中的位置

TODO: 看一下ali的blade然后总结一下

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200224012649.png)

### 2.2 优化细节

tensorflow官方提供了一些图优化的具体操作：

> - *Constant folding optimizer -* Statically infers the value of tensors when possible by folding constant nodes in the graph and materializes the result using constants.
> - *Arithmetic optimizer -* Simplifies arithmetic operations by eliminating common subexpressions and simplifying arithmetic statements.
> - *Layout optimizer -* Optimizes tensor layouts to execute data format dependent operations such as convolutions more efficiently.
> - *Remapper optimizer -* Remaps subgraphs onto more efficient implementations by replacing commonly occuring subgraphs with optimized fused monolithic kernels.
> - *Memory optimizer -* Analyzes the graph to inspect the peak memory usage for each operation and inserts CPU-GPU memory copy operations for swapping GPU memory to CPU to reduce the peak memory usage.
> - *Dependency optimizer -* Removes or rearranges control dependencies to shorten the critical path for a model step or enables other optimizations. Also removes nodes that are effectively no-ops such as Identity.
> - *Pruning optimizer -* Prunes nodes that have no effect on the output from the graph. It is usually run first to reduce the size of the graph and speed up processing in other Grappler passes.
> - *Function optimizer -* Optimizes the function library of a TensorFlow program and inlines function bodies to enable other inter-procedural optimizations.
> - *Shape optimizer -* Optimizes subgraphs that operate on shape and shape related information.
> - *Autoparallel optimizer -* Automatically parallelizes graphs by splitting along the batch dimension. This optimizer is turned OFF by default.
> - *Loop optimizer -* Optimizes the graph control flow by hoisting loop-invariant subgraphs out of loops and by removing redundant stack operations in loops. Also optimizes loops with statically known trip counts and removes statically known dead branches in conditionals.
> - *Scoped allocator optimizer -* Introduces scoped allocators to reduce data movement and to consolidate some operations.
> - *Pin to host optimizer -* Swaps small operations onto the CPU. This optimizer is turned OFF by default.
> - *Auto mixed precision optimizer -* Converts data types to float16 where applicable to improve performance. Currently applies only to GPUs.
> - *Debug stripper -* Strips nodes related to debugging operations such as [`tf.debugging.Assert`](https://www.tensorflow.org/api_docs/python/tf/debugging/Assert), [`tf.debugging.check_numerics`](https://www.tensorflow.org/api_docs/python/tf/debugging/check_numerics), and [`tf.print`](https://www.tensorflow.org/api_docs/python/tf/print) from the graph. This optimizer is turned OFF by default.

优化的好处：

1. 

### 周边工具

[TFX]https://github.com/tensorflow/tfx

[tensorflow model optimization toolkit](https://www.tensorflow.org/model_optimization)

## 3. pipeline

#### 3.1 图冷却

#### 3.2 图分析

#### 3.3 图精简与优化

