<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
---
layout:     post
title:      "OCR文档二值化算法"
subtitle:   " \"手持设备拍照源的OCR文档二值化处理\""
date:       2018-01-02 16:07:00
author:     "HeShuai"
header-img: "img/banner/telegram_bot.png"
catalog: true
tags:
    - 图像处理
    - OCR
---

# OCR文档二值化算法

> 本文主要是二值化算法在OCR中的应用调研总结。调研和实现了四种二值化算法，分别是大津全局二值化算法、动态二值化算法、循环背景差分二值化算法以及$Sauvola's$局部二值化算法。
> 结果显示，在**无光照影响的扫描图像中**，大津**全局二值化**算法的结果文字连通性更好，背景更干净，速度更快；**局部二值化**能**有效应对光照不均等情况**，但二值化文字的边缘存在毛刺，背景有较多噪音，计算资源要求大于全局二值化；所有通用的基于统计信息的二值化对较大面积且深度较高的干扰点和干扰块都无能为力，需要在二值化算法中整合文档图像或者文字的特定特征，使二值化算法具备区分文字前景和背景的能力，能区别地进行二值化操作。
> 二值化算法的选择，需要根据图像情况和处理时间要求进行选择。一般来说，**干扰有限且质量可控的应用中**（如印刷体）宜采用大津或者普通的局部二值化实现的二值化算法；**干扰多且不可控的应用**（如手持设备拍摄图像）宜采用则需要精细设计的局部二值化算法。

#### 关键字
> 二值化、全局二值化、局部二值化、OCR
#### 0. Introduction

##### 0.1 通用二值化

二值化算法是传统数字图像处理的基础，常作为图像处理与识别算法流程的预处理模块。其旨在保留图像中有意义的前景，其他则作为背景。图像二值化有以下好处：
1. 仅保留前景部分，去除不必要的噪音和干扰，对后面的算法起了一种类似值归一化的作用，提升后续各种图像处理算法或者模式识别算法的效果。
2. 二值化后的图像内存占用更小、计算更快，可以大幅度提升整体算法流程的运行效率。

二值化算法属于数字图像处理的**分割**算法，再上溯则是模式识别里的**分类**算法。其解决的问题就是：以最小的代价取一个分类平面，将所有像素分类成两个类别。但是”二值化算法“常常狭义地特指将**灰度图像**通过**取阈值**的形式分割成前后景。给定一个灰度图像$I$，其在$(i,j)$上的位置上的像素值为$I_{(i,j)}$，该点的二值化阈值为$T_{(i,j)}$, 则得到二值化结果$I_{binary(i,j)}$。整个过程只有一个未知量，即二值化阈值$T$，因此二值化的核心就在于$T$如何求取。

$T$本质上就是二值分类的分类平面，$T$取的质量直接决定了二值化效果的好坏。从模式识别的角度，$T$的取值方法很多，简单如hard code的常量、无监督算法如基于统计信息分析和聚类等，以及需要在线学习的有监督算法。目前绝大多数教材中的二值化算法其实仅特指基于常量和区域统计信息分析的阈值选取算法。

常量阈值是最简单粗暴的方法，但是常量意味着适用性的丢失，会出现一个图一个效果的现象。更好的方法是动态阈值选择，现有的二值化算法几乎都基于区域统计信息的方法，如统计灰度直方图等。根据统计区域的大小不同，可大概分为**全局**二值法和**局部**二值法。

>全局二值法：统计图像中所有的像素点信息，得到一个阈值，该阈值与位置无关，即所有的像素分割均采用该阈值。经典算法有大津二值化算法。
>
>局部二值化：统计某位置像素点周边一定区域的信息，每个位置均得到一个二值阈值，因此又称为动态二值法。该方法能够有效应对同一图像内方差大的情况，如光照不均匀和非均匀干扰等；统计区域大小可以根据实际情况而定，当统计区域为整个图像时，此时局部二值化就变成了全局二值化。

|    算法    |                             特点                             |                            优缺点                            |    经典算法    |
| :--------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :------------: |
| 全局二值化 |    根据全图统计信息得到一个阈值，所有像素位置均采用该阈值    |    计算速度快，但是适应性差，只能用于高质量的扫描OCR等。     |      大津      |
| 局部二值化 | 针对每个像素位置，在其附近小范围区域内统计信息得到一个阈值，因此同一图像内不同位置的阈值都不一样 | 计算速度慢，但是适应性强。更可能应用于噪声不可控的实际场景中。 | 高斯动态二值化 |

##### 0.2 OCR二值化问题分析

OCR处理目的是将文本图形中关键内容（如文字公式等）进行提取以进行后续识别。相比较于日常媒体图像数据，OCR图像来源与扫描或者手持设备拍摄，一般为白底黑字，因此对二值化具有先天的适应性。然而，文本图像中仍存在运动模糊、镜头模糊、干扰墨迹、光照不均等情况。要求二值化算法能够尽可能准确地提取文本部分，而且提取的文本背景具有高识别度，以进行后续OCR算法识别。

#### 1. 预处理

由于图像存在运动模糊以及其他类型的噪音影响，图像中的像素值并非是平滑的，会存在异常值（尤其是高梯度附近区域）。采用统计信息所得的阈值先天地无法应对这部分异常值像素，因此会出现雪霜或者杂块的二值化结果（如下图）。

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724232846.png)

因此首先要对图像进行去噪和增强。去噪和增强的具体方法就是滤波，相当于频域上的高低带通，保留需要的频段信号。常见的低通滤波算子如高斯滤波等，其虽然能有效平滑毛刺像素值，但是其空间位置无差别地滤波会影响需要保留的高梯度区域，导致图像模糊。因此图像的预处理部分既需要平滑毛刺，又需要保梯度。双边滤波和导向滤波是符合要求的两种方法。以下是经过双边滤波再进行二值化的结果。

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724232904.png)

#### 2. 全局二值化
全局二值化所有像素点采用统一的阈值，可以有效应对灰度均匀或者平缓变化的图像，且计算速度相对局部二值化相对更优。二值化阈值多来源于全局图像信息分析，如直方图统计。
**大津二值化**算法是全局二值化中的突出代表，其搜索在0-255之间进行阈值搜索，目标使二值化后的类间方差最大化。大津二值化算法在扫描图像中（无光照不均、大面积斑块）表现较好。其结果的文字边缘毛刺现象较轻、文字二值化后连通性更好且速度极快。可见下图对比：

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724233018.png)

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724233026.png)

#### 3. 动态二值化

与全局二值化算法考虑全局信息不同，局部二值化算法集中更多的**注意力在局部**范围内，但也并非只考虑局部，**同时整合全局**的统计信息可以做到局部与全局兼顾。除此之外，还需要考虑不同图像之间的差异性。因此真正的动态二值化的动态有两层含义：

> 1. 同一图像内不同像素位置的动态。
>
> 2. 不同图像之间的动态。

该部分主要涉及我测试到的三种算法：**高斯动态二值化**、**循环去背景动态二值化**以及针对文本数据的**Sauvola's动态二值化**算法。   

##### 3. 1 高斯动态二值化算法

高斯动态二值化算法是比较基础的局部二值化算法，其考虑固定窗口$W$内的灰度值的高斯加权和。当然，广义的局部二值化还可以采用均值、中值等其他加权方式。其表达形式：
$$
T = \sum \delta_{w}I_{w} - Cons \\
$$
$\sum \delta_wI_w$为$W$窗口加权和，加权方式常见有高斯平均与平均两种。常数$Cons$为偏置修正量，所有像素共享与位置无关。

$Cons$的大小极大影响着二值化效果，主要是准确率与召回率之间的权衡。当C比较小，文字部分的召回率更高，视觉体现是字体部分二值化结果清晰、连通性好。但是背景部分会出现误检测，出现大量的杂质和噪音。另$Cons$ Hardcode式的选取方法使其数据间适应性较差，不同批样的图片需要人工重新调试选择。
针对常量$C$需要人工调试这一缺点，有一个改进方法是将cons表达为全局均值与方法的函数，因此每个图像都有一个对应的常量。其 表达式：
$$
Cons = f(m_{global}, std_{global}) \\
T = m_{local} - Cons \\
m = \sum \delta_wI_w
$$
$Cons$表示式的选取需要人工尝试，经验下$Cons = 0.05m$可获得一定的通用效果。

尽管如此，由于所有像素点共用一个$Cons$，当背景出现较黑斑点时，无法考虑局部的情况，进行有效的抑制。所以这种方法是一种完全局部二值化算法。

##### 3.2 Sauvola's局部二值化算法

对于基于opencv动态二值化算法的无视局部信息的缺点，Sauvola's在不同的像素位置引入不同的偏差，由于加入和全局方差动态范围参数R，局部信息中加入全局方差对比信息，使得在全局图像中，方差大的区域（潜在存在文字区域）像素点阈值更高，方差小的区域（背景区域）阈值更低。表达式[1]：
$$
T = m  [1 + K(\frac{s}{R} - 1)] \\
$$
其中$\frac{m}{s}$为局部均值方差，R为方差动态范围，k为阈值。

R为全局方差的动态范围。注意在论文中取为128，但实际不可用。R需要反映局部方差在全图中的统计信息，经验可取为区域方差统计的中值、均值或者最大值。K与R一起影响着对背景与文字区域的二值化区分度，一般来说，k越大，R越小，两者差别越大，背景越干净，但文字二值化连通性更差。经验下:
$$
k = 0.1 \\
R = \frac{max(std_{global})}{3}
$$
由于$Sauvola's$需要计算所有区域的均值与方差，计算速度比只算均值局部动态二值化算法更慢。

##### 3.3 循环背景差分二值化算法

参考于[1]，主要思想是循环地减去全局平均灰度再进行直方图均衡化，最终当全局平均灰度小于一定阈值后再进行二值化操作。本质上该算法可看做二值化操作之前的平滑去背景操作。但由于是全局操作，在实际中对光照不均以及干扰斑块消除效果微乎其微，没有达到去背景效果。最终结果不如论文展示。
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/%E5%BE%AA%E7%8E%AF%E5%B7%AE%E5%88%86%E4%BA%8C%E5%80%BC%E5%8C%96.png)

#### Summary

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/%E4%BA%8C%E5%80%BC%E5%8C%96%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94.png)
<center>P_5: 从左到右分别为原图、基于opencv动态二值化、$Sauvola's$、循环背景差分、大津</center>
扫描图像（少干扰）：
$$
基于opencv动态二值化 <= 大津二值化 <=  Sauvola's
$$
手持设备拍照（光照不均）：
$$
大津二值化 << 基于opencv动态二值化 <= Sauvola's
$$
运行速度：
$$
Sauvola's < 基于opencv动态二值化 < 全局二值化（大津等）
$$

上述讨论涉及的二值化算法实际上都可作为通用的二值化算法，很少为文本特定特征作优化。调研过程中，发现大部分论文均在$Sauvols's$二值化上加入各种预处理与后处理，算法流程较为复杂。从$Sauvola's$的结果可发现，最好的二值化算法应该是全局与局部结合，在局部阈值当中加入全局信息（突出背景与文字的差别），加入的全局信息可以如$Sauvola's$中的方差动态范围，还可以如连通域分析或者聚类分析（水漫算法），或者其他文档特有的特征信息。日后如果需要加强二值化效果，可以往这个方向思考（全局与局部结合）。另外，老生常谈：速度与效果不可兼得。

#### 拓展分析-基于深度学习的二值化算法

//TODO

#### Referecne

[1] Adaptive document image binarization
[2] A Binarization Algorithm specialized on Document Images and Photos
---
layout:     post
title:      "OCR文档二值化算法"
subtitle:   " \"手持设备拍照源的OCR文档二值化处理\""
date:       2018-01-02 16:07:00
author:     "HeShuai"
header-img: "img/banner/telegram_bot.png"
catalog: true
tags:
    - 图像处理
    - OCR
---

# OCR文档二值化算法

> 本文主要是二值化算法在OCR中的应用调研总结。调研和实现了四种二值化算法，分别是大津全局二值化算法、动态二值化算法、循环背景差分二值化算法以及$Sauvola's$局部二值化算法。
> 结果显示，在**无光照影响的扫描图像中**，大津**全局二值化**算法的结果文字连通性更好，背景更干净，速度更快；**局部二值化**能**有效应对光照不均等情况**，但二值化文字的边缘存在毛刺，背景有较多噪音，计算资源要求大于全局二值化；所有通用的基于统计信息的二值化对较大面积且深度较高的干扰点和干扰块都无能为力，需要在二值化算法中整合文档图像或者文字的特定特征，使二值化算法具备区分文字前景和背景的能力，能区别地进行二值化操作。
> 二值化算法的选择，需要根据图像情况和处理时间要求进行选择。一般来说，**干扰有限且质量可控的应用中**（如印刷体）宜采用大津或者普通的局部二值化实现的二值化算法；**干扰多且不可控的应用**（如手持设备拍摄图像）宜采用则需要精细设计的局部二值化算法。

#### 关键字
> 二值化、全局二值化、局部二值化、OCR
#### 0. Introduction

##### 0.1 通用二值化

二值化算法是传统数字图像处理的基础，常作为图像处理与识别算法流程的预处理模块。其旨在保留图像中有意义的前景，其他则作为背景。图像二值化有以下好处：
1. 仅保留前景部分，去除不必要的噪音和干扰，对后面的算法起了一种类似值归一化的作用，提升后续各种图像处理算法或者模式识别算法的效果。
2. 二值化后的图像内存占用更小、计算更快，可以大幅度提升整体算法流程的运行效率。

二值化算法属于数字图像处理的**分割**算法，再上溯则是模式识别里的**分类**算法。其解决的问题就是：以最小的代价取一个分类平面，将所有像素分类成两个类别。但是”二值化算法“常常狭义地特指将**灰度图像**通过**取阈值**的形式分割成前后景。给定一个灰度图像$I$，其在$(i,j)$上的位置上的像素值为$I_{(i,j)}$，该点的二值化阈值为$T_{(i,j)}$, 则得到二值化结果$I_{binary(i,j)}$。整个过程只有一个未知量，即二值化阈值$T$，因此二值化的核心就在于$T$如何求取。

$T$本质上就是二值分类的分类平面，$T$取的质量直接决定了二值化效果的好坏。从模式识别的角度，$T$的取值方法很多，简单如hard code的常量、无监督算法如基于统计信息分析和聚类等，以及需要在线学习的有监督算法。目前绝大多数教材中的二值化算法其实仅特指基于常量和区域统计信息分析的阈值选取算法。

常量阈值是最简单粗暴的方法，但是常量意味着适用性的丢失，会出现一个图一个效果的现象。更好的方法是动态阈值选择，现有的二值化算法几乎都基于区域统计信息的方法，如统计灰度直方图等。根据统计区域的大小不同，可大概分为**全局**二值法和**局部**二值法。

>全局二值法：统计图像中所有的像素点信息，得到一个阈值，该阈值与位置无关，即所有的像素分割均采用该阈值。经典算法有大津二值化算法。
>
>局部二值化：统计某位置像素点周边一定区域的信息，每个位置均得到一个二值阈值，因此又称为动态二值法。该方法能够有效应对同一图像内方差大的情况，如光照不均匀和非均匀干扰等；统计区域大小可以根据实际情况而定，当统计区域为整个图像时，此时局部二值化就变成了全局二值化。

|    算法    |                             特点                             |                            优缺点                            |    经典算法    |
| :--------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :------------: |
| 全局二值化 |    根据全图统计信息得到一个阈值，所有像素位置均采用该阈值    |    计算速度快，但是适应性差，只能用于高质量的扫描OCR等。     |      大津      |
| 局部二值化 | 针对每个像素位置，在其附近小范围区域内统计信息得到一个阈值，因此同一图像内不同位置的阈值都不一样 | 计算速度慢，但是适应性强。更可能应用于噪声不可控的实际场景中。 | 高斯动态二值化 |

##### 0.2 OCR二值化问题分析

OCR处理目的是将文本图形中关键内容（如文字公式等）进行提取以进行后续识别。相比较于日常媒体图像数据，OCR图像来源与扫描或者手持设备拍摄，一般为白底黑字，因此对二值化具有先天的适应性。然而，文本图像中仍存在运动模糊、镜头模糊、干扰墨迹、光照不均等情况。要求二值化算法能够尽可能准确地提取文本部分，而且提取的文本背景具有高识别度，以进行后续OCR算法识别。

#### 1. 预处理

由于图像存在运动模糊以及其他类型的噪音影响，图像中的像素值并非是平滑的，会存在异常值（尤其是高梯度附近区域）。采用统计信息所得的阈值先天地无法应对这部分异常值像素，因此会出现雪霜或者杂块的二值化结果（如下图）。

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724232846.png)

因此首先要对图像进行去噪和增强。去噪和增强的具体方法就是滤波，相当于频域上的高低带通，保留需要的频段信号。常见的低通滤波算子如高斯滤波等，其虽然能有效平滑毛刺像素值，但是其空间位置无差别地滤波会影响需要保留的高梯度区域，导致图像模糊。因此图像的预处理部分既需要平滑毛刺，又需要保梯度。双边滤波和导向滤波是符合要求的两种方法。以下是经过双边滤波再进行二值化的结果。

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724232904.png)

#### 2. 全局二值化
全局二值化所有像素点采用统一的阈值，可以有效应对灰度均匀或者平缓变化的图像，且计算速度相对局部二值化相对更优。二值化阈值多来源于全局图像信息分析，如直方图统计。
**大津二值化**算法是全局二值化中的突出代表，其搜索在0-255之间进行阈值搜索，目标使二值化后的类间方差最大化。大津二值化算法在扫描图像中（无光照不均、大面积斑块）表现较好。其结果的文字边缘毛刺现象较轻、文字二值化后连通性更好且速度极快。可见下图对比：

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724233018.png)

![](https://raw.githubusercontent.com/mightycatty/mightycatty.github.io/master/img/20190724233026.png)

#### 3. 动态二值化

与全局二值化算法考虑全局信息不同，局部二值化算法集中更多的**注意力在局部**范围内，但也并非只考虑局部，**同时整合全局**的统计信息可以做到局部与全局兼顾。除此之外，还需要考虑不同图像之间的差异性。因此真正的动态二值化的动态有两层含义：

> 1. 同一图像内不同像素位置的动态。
>
> 2. 不同图像之间的动态。

该部分主要涉及我测试到的三种算法：**高斯动态二值化**、**循环去背景动态二值化**以及针对文本数据的**Sauvola's动态二值化**算法。   

##### 3. 1 高斯动态二值化算法

高斯动态二值化算法是比较基础的局部二值化算法，其考虑固定窗口$W$内的灰度值的高斯加权和。当然，广义的局部二值化还可以采用均值、中值等其他加权方式。其表达形式：
$$
T = \sum \delta_{w}I_{w} - Cons \\
$$
$\sum \delta_wI_w$为$W$窗口加权和，加权方式常见有高斯平均与平均两种。常数$Cons$为偏置修正量，所有像素共享与位置无关。

$Cons$的大小极大影响着二值化效果，主要是准确率与召回率之间的权衡。当C比较小，文字部分的召回率更高，视觉体现是字体部分二值化结果清晰、连通性好。但是背景部分会出现误检测，出现大量的杂质和噪音。另$Cons$ Hardcode式的选取方法使其数据间适应性较差，不同批样的图片需要人工重新调试选择。
针对常量$C$需要人工调试这一缺点，有一个改进方法是将cons表达为全局均值与方法的函数，因此每个图像都有一个对应的常量。其 表达式：
$$
Cons = f(m_{global}, std_{global}) \\
T = m_{local} - Cons \\
m = \sum \delta_wI_w
$$
$Cons$表示式的选取需要人工尝试，经验下$Cons = 0.05m$可获得一定的通用效果。

尽管如此，由于所有像素点共用一个$Cons$，当背景出现较黑斑点时，无法考虑局部的情况，进行有效的抑制。所以这种方法是一种完全局部二值化算法。

##### 3.2 Sauvola's局部二值化算法

对于基于opencv动态二值化算法的无视局部信息的缺点，Sauvola's在不同的像素位置引入不同的偏差，由于加入和全局方差动态范围参数R，局部信息中加入全局方差对比信息，使得在全局图像中，方差大的区域（潜在存在文字区域）像素点阈值更高，方差小的区域（背景区域）阈值更低。表达式[1]：
$$
T = m  [1 + K(\frac{s}{R} - 1)] \\
$$
其中$\frac{m}{s}$为局部均值方差，R为方差动态范围，k为阈值。

R为全局方差的动态范围。注意在论文中取为128，但实际不可用。R需要反映局部方差在全图中的统计信息，经验可取为区域方差统计的中值、均值或者最大值。K与R一起影响着对背景与文字区域的二值化区分度，一般来说，k越大，R越小，两者差别越大，背景越干净，但文字二值化连通性更差。经验下:
$$
k = 0.1 \\
R = \frac{max(std_{global})}{3}
$$
由于$Sauvola's$需要计算所有区域的均值与方差，计算速度比只算均值局部动态二值化算法更慢。

##### 3.3 循环背景差分二值化算法

参考于[1]，主要思想是循环地减去全局平均灰度再进行直方图均衡化，最终当全局平均灰度小于一定阈值后再进行二值化操作。本质上该算法可看做二值化操作之前的平滑去背景操作。但由于是全局操作，在实际中对光照不均以及干扰斑块消除效果微乎其微，没有达到去背景效果。最终结果不如论文展示。
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/%E5%BE%AA%E7%8E%AF%E5%B7%AE%E5%88%86%E4%BA%8C%E5%80%BC%E5%8C%96.png)

#### Summary

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/%E4%BA%8C%E5%80%BC%E5%8C%96%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94.png)
<center>P_5: 从左到右分别为原图、基于opencv动态二值化、$Sauvola's$、循环背景差分、大津</center>
扫描图像（少干扰）：
$$
基于opencv动态二值化 <= 大津二值化 <=  Sauvola's
$$
手持设备拍照（光照不均）：
$$
大津二值化 << 基于opencv动态二值化 <= Sauvola's
$$
运行速度：
$$
Sauvola's < 基于opencv动态二值化 < 全局二值化（大津等）
$$


上述讨论涉及的二值化算法实际上都可作为通用的二值化算法，很少为文本特定特征作优化。调研过程中，发现大部分论文均在$Sauvols's$二值化上加入各种预处理与后处理，算法流程较为复杂。从$Sauvola's$的结果可发现，最好的二值化算法应该是全局与局部结合，在局部阈值当中加入全局信息（突出背景与文字的差别），加入的全局信息可以如$Sauvola's$中的方差动态范围，还可以如连通域分析或者聚类分析（水漫算法），或者其他文档特有的特征信息。日后如果需要加强二值化效果，可以往这个方向思考（全局与局部结合）。另外，老生常谈：速度与效果不可兼得。

#### 拓展分析-基于深度学习的二值化算法

//TODO

#### Referecne

[1] Adaptive document image binarization

[2] A Binarization Algorithm specialized on Document Images and Photos
