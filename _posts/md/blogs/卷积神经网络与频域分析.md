# 卷积神经网络与频域分析


##### 论文阅读笔记
###### [Spectral Representation For Convolutional Neural Networks](https://arxiv.org/pdf/1906.08988.pdf)

文章从频谱角度对模型的鲁棒性进行研究。试图说明不同的数据增广方法在不同频段corrupt下的数据表现是不一样的。
**文章关键点： **

1. 低通滤波相关（高斯模糊 ）的增强方法可以使模型对高频噪音更鲁棒，但是低通噪音数据表现有所退化；反之反转
2. 自然数据的频谱集中在低频区域，也就是1中提到的性能退化使得自然数据也出现退化。
3. 附带的数据似乎说明单一的增强虽然可以提升模型在非寻常corrupted（人为）数据的表现，但是自然数据丝毫没有提升。
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/%E6%A8%A1%E5%9E%8B%E9%B2%81%E6%A3%92%E6%80%A7%E5%88%86%E6%9E%90.png)
4. 文章重点表扬了一下Auto Augmentation的表现，实验结果表现为起能够提升中低段噪音的性能（更接近自然数据），最重要的时，它真实提升了原始验证集的表现。
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/model_on_corrupted_data.png)
5. 不同数据增强方式对数据平均频谱的影响

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images/%E9%A2%91%E8%B0%B1-%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF.png)

**个人想法和疑问**
1. Augmentation不是任意加的，也非越多越好。经验下过度过强的Aug会降低测试集的精度。
2. 一些人为的数据增广是否是有必要的，如一些滤波相关算子。这些算子虽然能提升模型在某些数据上的表现，但是在最关注的原始数据下却出现了退化，而且提升的数据corrupt模式是否会在真实数据中产生，是否太人为和刻意了？
3. 数据增广方法的选择应该考虑实际数据的分布。假设测试集是真实分布的有效采样，增广的方式应该从分析测试集的分布而选取。如果不是有效采样，应该估计和分析真实数据会出现的data corrupt。
   4. 模型泛化能力的实际就是希望模型拟合的分布与真实分布的KL距离尽可能地小。数据增广应该缩小训练与实际数据的KL距离，而非逆方向而行。

##### Reference

[1] [Spectral Representation For Convolutional Neural Networks](https://arxiv.org/pdf/1906.08988.pdf)