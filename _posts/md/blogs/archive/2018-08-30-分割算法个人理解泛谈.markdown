---
layout:     post
title:      "分割算法个人理解泛谈"
subtitle:   " \"个人对分割算法的总结、理解和泛泛之谈\""
date:       2018-08-30 18:38:00
author:     "HeShuai"
header-img: "img/banner/seg.png"
catalog: true
tags:
    - 图像处理
    - 深度学习
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
# 分割算法个人理解泛谈

#### 前话

>本文主要是本人对分割算法的一些理论总结和个人理解总结，针对的是静态帧分割图像分割。由于个人水平有限或者表达错误，可能会存在一些错误，如果各位大佬指点指点噢:smile:

#### 概要

>  完整的分割算法流程需要考虑全局语意信息和局部像素级低层次信息，视频流的分割还需要考虑时序信息。传统的分割算法多基于图论算法，分辨率增大会导致计算量的指数增加，且优化函数天然倾向于低层次特征，导致明显语意差别的相似区域被分割成一类。由于卷积具有强大的多维度（如图像中的2D）特征提取能力和抽象能力，深层CNN为分割提供了语意层次信息提取的可能。但基于CNN的分割本质是空间分类，相邻的像素点分类结果无图论节点间的强联合关系，无视物体的拓扑结构，导致容易出现游离脏块，且CNN的过度平滑效应使边缘拟合较差。目前的发展趋势是深度学习和图论算法结合，但推理计算量限制了该类算法的实时性应用。

#### 关键字

> 深度学习、分割算法

#### 0. Introduction

对分割算法中的语意特征和像素级特征进行独立考虑，可将分割算法大致分为图论算法和深度学习两个分支：图论算法和深度学习算法。图论算法将图像构建为一个无向图结构，图节点为原图像的像素或者超像素。节点间连接权重为相似度衡量特征，与两节点间的相似程度成反比。分割问题最终转化为图分割问题，采用最大流/最小割分割算法，将图像像素节点之间的连接断开，得到前后景分割结果（两类情况）。切开的连接权重之和可认为是分割代价，因此从优化角度是一个能量（代价）最小化问题。图论中根据图的构建方法不同衍生不同的具体算法。其中最著名的有graphcut算法和CRF算法。最大流算法是一个枚举过程，或者借助拉氏矩阵分解，计算量随节点数成指数增加，常规桌面电脑需要秒级以上的处理时间。 深度学习算法利用CNN操作构建特征塔，最终得到每个像素对应的语意特征向量（由于下采样的存在，最终得到的某个点的特征为原图像下采样个倍数的像素的共同特征），并假设该特征线性可分，利用softmax进行空间分类。深度学习能自适应地提取相关语意信息，但是由于特征塔层数过高，且由于网络结构中MAXPOOL等模块的非线性操作，导致最终特征图谱与原图像出现位置或者特征信息偏差，可视化表现为边缘拟合差、过渡平滑。空间分类Loss的使用导致了分割结果中前景和后景的聚合无视被分割物体的拓扑结构。本文将会对上述两种算法进行优劣点的分析，得到分割任务的通用设计框架，为后续的算法优化提供指导方向。

#### 1. 传统图论算法

根据图构建方法和节点间权值定义的不同，区别出不同的算法，本文仅讨论经典的Graphcut算法和与深度学习结合有经验性奇效的CRF算法。
##### 1.1 Graphcut

Graph cuts[1]为能量优化算法，应用于前背景分割（Image segmentation）、立体视觉（stereo vision）、抠图（Image matting）等。该方法把图像分割问题转换为图的最小割（mincut）问题。

算法核心步骤如下：

1. 构建无向图G=<V，E>
以表示要分割的图像。V和E为顶点（vertex）与边（edge）的集合，节点对应原图的像素点。graphcut图有以下特征：
   - 所有节点仅与附近节点连接
   - 节点间的边为相似度衡量
   -  在普通图的基础上多了2个顶点，分别表示为”S”和”T‘’，理解为前后景节点
   -  各普通节点与ST的边权重为其属于前后景的概率的负指数幂
    ![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204184909.png)

2. 节点连接权重的确定
- 普通节点与TS节点的连接权重：
  为其属于前景后景的概率的负指数幂，表现为概率越大，权重越小。该权重为一元势能函数，仅与当前节点有关，与领域节点无关，因此可认为是前后景语意势能图，由概率分类器提供，如GMM模型或者深度学习模型。
- 普通节点之间的连接权重：
  为两个节点的相似度衡量。相似度衡量特征有多重选择，如图像梯度、颜色、位置或者兼而之，常见的有五维特征（LAB-XY）。相似度越高，权重越小。


3. 最大流/最小割分割
    最小割的总体思想为将某些节点的边断开，最终得到两个子图，即为分割结果。分割代价为断边权重之和。
    由目标函数分析可见，TS与普通节点间的权重抑制预分类前后景的错误分割；普通节点间的权重则倾向于把底层特征相似度高的像素分割成同一类，两者协同达到语意层次特征与像素级特征综合考虑的结果。

  ![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204191441.png)

##### 2.2 CRF
CRF的目标函数基本与Graphcut[2]算法一致，区别有以下几点：

- 节点连接不仅仅是相邻像素，可以跨节点连接，最极端的算法为DenseCRF[3]，即所有的节点（像素点）之间都存在边。
- 上述图结构带来计算量上的指数级剧增，因此有针对性的推理优化算法，如DenseCRF的mean field approximation（领域变分）[3][4]，通过最小化KL散度来近似。
- 不存在显性的TS节点，但优化能量函数中仍有与Grapcut一样的一元前后景势能函数。

##### 2.3 最大流/最小割算法
图论最大流求解算法，参见[5]，兹不详述。

#### 3. 深度学习分割算法
在基于深度学习发源于FCN，即fully convolutional network。该通用分割框架中，CNN+pooling组合可近似看做多尺度理论中金字塔的构建过程，存在诸多问题。

- pool操作相当于金字塔中的加权downsample，其优点:
  - 能指数倍地降低feature map的分辨率，大幅度降低后续卷积操作的计算量
  - 保留高层次抽象信息，丢弃无用细节特征
  - 指数倍地增加感受野，增强CNN对全局信息的感受[6]

- pooling结构的缺点也显而易见
  - 得到的feature map分辨率小于原图，因此feature map上一个点的特征向量为原图n个点的共同特征向量，导致分割结果的精细度下降
  - 非线性pool，如maxpool，会破坏feature map与原图的线性位置映射
  - maxpool取区域内特征的最高响应，当某些区域背景特征强于前景特征时，如小物体附近区域，容易造成分割或者检测丢失
  - pool进一步提升了特征的抽象程度，但对于上一级金字塔比较相似的区域，极端如average pooling会导致不同点间的特征差异完全丢失

- CNN卷积操作
  - 传统算法中的梯度算子与滤波为CNN卷积操作的特例；梯度算子提取图像边缘，抛弃平滑区域的特征差异；滤波如高斯滤波或者均值滤波，其平滑效果，降低或者减弱相似区域内的像素点特征差异。
  - CNN为自学习算子，根据样本进行filter学习，针对性地进行有监督特征提取，实验表现优于人工定义的特征。
  - CNN与POOL相似，大量的操作会导致低层次细节信息的丢失。在分类问题中，该作用起积极用途，但在生成式问题中，还原成原分辨率的图像需要考虑低层次的特征信息，CNN得到的过平滑语意信息不足以恢复成原分辨率大小的分割结果。
  - CNN过度依赖于颜色特征，物体结构提取能力较弱；y=wx+b本质上是标量运算，能感知某类特征（如人眼耳口鼻）的存在，却无法感知特征之间的拓扑关系。实验表现为纯灰度（由于颜色信息丢失，只能根据物体形状进行分割）的图片在iou0.2左右即无法进一步收敛。

- Loss
  - 目前几乎所有主流框架采用的都是binary cross entropy loss，最终分割问题等价于空间分类问题。假设最终的feature map大小为64*64*256，softmax层相当于于64*64个256维特征的样本进行分类。样本间的分类在不考虑前面CNN卷积引起的弱关联情况下，各个像素点的分类是独立的。因此softmax实际上是一种无视物体拓扑结构的Loss设置。

针对上述问题，目前的start-of-art分割框架主要有两种流派[7]：

- 漏斗形结构
  代表框架：Segnet、Unet
  针对前文分析的CNN问题，该流派有以下设计应对：
  - encoder/pooling+decoder/upsample结构。该操作优点：浓缩语意特征、大幅度降低计算量（相对长筒型网络）、足够的感受野大小以提取语意特征。
  - shortcut结构。将encoder层的特征通过一定手段融合到对应的decoder的层中，进行像素位置align和语意特征\底层信息融合。

- 插孔卷积金字塔结构

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204185448.png)
![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204185506.png)
代表框架：Deeplab、PSPNet
结构设计：

- 金字塔结构如ASPP in deeplab\PPM in PSPNet是该流派的精髓，在CNN特征而非原图上构建金字塔
  ASPP的本质就是自适应金字塔。CNN插空卷积等价于金字塔构建过程的高斯滤波+downsample，但是滤波算子不是高斯算子，而是可训练的。
- ASPP效果与传统金字塔结构相似，构建多尺度特征，应对物体的大小尺度不一问题
  ASPP中插孔卷积算子的加入，在不增加任何计算量的情况下，2次倍数地增加感受野大小，且不会造成特征-像素之间的位置对应精度损失
- 由于大感受野在ASPP中即可取得，因此encoder相对沙漏流派层数可以更少（后者依靠pool操作增加感受野）

State of Art网络结构见排名[8]

#### 3. 联合分析
实际上，联合打通深度学习与传统图论算法，其优化能量函数可以表示为：
$$
E(x)=\sum \delta_{u}(x_i) + \sum \delta_p(x_i, x_j)
$$

##### 3.1 $$ \sum \delta_{u}(x_i)$$

 为一元势能，表示二维图像中的前景后景势能图。势能越大的地方越可能是前景。可理解为**语意层次特征**

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204190944.png)

在优化过程相当于分割代价最小化，地势越高的地方分割为背景的代价越高，因此优化过程会尽量避免对高势能区域的误分割。传统算法中，该一元势能量来自于弱分类器，如GMM模型。深度学习的兴起，取代了GMM，可以获得更精确的势能图，其优化函数等价于（无视第二项平滑因子）：
$$
E(x)=\sum \delta_{u}(x_i)
$$
但是由于章节3提到的深度学习的缺点，纯深度学习分割结果边缘精度较差。

3.2 $$\sum \delta_p(x_i, x_j)$$

​    pairwise能量部分，考虑分割前景和背景之间的差异度。**可理解为低层次特征。**在优化过程中，会倾向于把既定特征（如颜色位置等）相似的像素点分割为不同子集。相对于深度学习，该项的作用：

- 其考虑了两个像素点之间的label关系，一定程度上可以理解为像素点之间的拓扑结构
- 表征差异度的特征为低层次特征，如颜色位置，特征抽象度更低，因此在生成式模型中，有足够信息可以还原同分辨率的分割结果

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204191210.png)

#####  3.3 wrapup

通过二项能量联合项优化，既考虑了语意特征，又考虑了低层次信息。语意特征指导大致分割区域，低层次特征提升边缘精度。串行结构的CNN结构会造成信息的丢失，因此难以还原成原图分辨率的分割结果。在最近的网络设计中，大家将CNN前端部分的中间特征作为低层次特征，融合到后端特征中，以间接取代能量优化函数的pairwise部分。从目前结果看，边缘部分尤有待提高。

![](https://raw.githubusercontent.com/mightycatty/image_bed/master/images20200204191525.png)

#### Referecne

[1] https://blog. csdn.net/zouxy09/article/details/8532111

[2] https://zhuanlan.zhihu.com/p/22464581

[3] Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials

[4] https://arxiv.org/pdf/1805.04777.pdf

[5] https://blog.csdn.net/v_JULY_v/article/details/40738211

[6] https://medium.com/@nikasa1889/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807

[7] http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review

[8] http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6